{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1lOfydXgpVthXlP3j2XZP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sujitrajt/NeuralNetwork/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wqaundh8zSj",
        "outputId": "8d6d5a72-a878-4ada-9a5d-37051126854d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n"
          ]
        }
      ],
      "source": [
        "print(\"Hello World\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "I7YpG2Y9JRTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetching the dataset using tensorflow\n",
        "(X_train,y_train),(X_test,y_test)=datasets.cifar10.load_data()\n",
        "X_train.shape #(50000,32,32,3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMRzoIiGJos3",
        "outputId": "e83dde1d-592a-4863-f492-3c3176fa2efa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape #Gives the number of sample size , size of the pixels and rgb model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_kzMPcVKP58",
        "outputId": "a257ec65-ac98-4162-f14d-6f9fe6e72255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the 2d array into 1d array as we can easily match with the labels\n",
        "y_train=y_train.reshape(-1,)\n",
        "y_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_Js0roPKP7S",
        "outputId": "199ca8b7-91eb-4568-f808-83c194472e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 9, 9, ..., 9, 1, 1], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test = y_test.reshape(-1,)"
      ],
      "metadata": {
        "id": "l7taLjHrcbAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3swKxWZsckIy",
        "outputId": "9ceda9c4-3744-4e82-a81f-d127d3faa41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 8, 8, ..., 5, 1, 7], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "id": "GonFfLtrbz6y",
        "outputId": "0589dfac-c3bc-4250-fd70-1c800eb6f15f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.61960784, 0.43921569, 0.19215686],\n",
              "         [0.62352941, 0.43529412, 0.18431373],\n",
              "         [0.64705882, 0.45490196, 0.2       ],\n",
              "         ...,\n",
              "         [0.5372549 , 0.37254902, 0.14117647],\n",
              "         [0.49411765, 0.35686275, 0.14117647],\n",
              "         [0.45490196, 0.33333333, 0.12941176]],\n",
              "\n",
              "        [[0.59607843, 0.43921569, 0.2       ],\n",
              "         [0.59215686, 0.43137255, 0.15686275],\n",
              "         [0.62352941, 0.44705882, 0.17647059],\n",
              "         ...,\n",
              "         [0.53333333, 0.37254902, 0.12156863],\n",
              "         [0.49019608, 0.35686275, 0.1254902 ],\n",
              "         [0.46666667, 0.34509804, 0.13333333]],\n",
              "\n",
              "        [[0.59215686, 0.43137255, 0.18431373],\n",
              "         [0.59215686, 0.42745098, 0.12941176],\n",
              "         [0.61960784, 0.43529412, 0.14117647],\n",
              "         ...,\n",
              "         [0.54509804, 0.38431373, 0.13333333],\n",
              "         [0.50980392, 0.37254902, 0.13333333],\n",
              "         [0.47058824, 0.34901961, 0.12941176]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.26666667, 0.48627451, 0.69411765],\n",
              "         [0.16470588, 0.39215686, 0.58039216],\n",
              "         [0.12156863, 0.34509804, 0.5372549 ],\n",
              "         ...,\n",
              "         [0.14901961, 0.38039216, 0.57254902],\n",
              "         [0.05098039, 0.25098039, 0.42352941],\n",
              "         [0.15686275, 0.33333333, 0.49803922]],\n",
              "\n",
              "        [[0.23921569, 0.45490196, 0.65882353],\n",
              "         [0.19215686, 0.4       , 0.58039216],\n",
              "         [0.1372549 , 0.33333333, 0.51764706],\n",
              "         ...,\n",
              "         [0.10196078, 0.32156863, 0.50980392],\n",
              "         [0.11372549, 0.32156863, 0.49411765],\n",
              "         [0.07843137, 0.25098039, 0.41960784]],\n",
              "\n",
              "        [[0.21176471, 0.41960784, 0.62745098],\n",
              "         [0.21960784, 0.41176471, 0.58431373],\n",
              "         [0.17647059, 0.34901961, 0.51764706],\n",
              "         ...,\n",
              "         [0.09411765, 0.30196078, 0.48627451],\n",
              "         [0.13333333, 0.32941176, 0.50588235],\n",
              "         [0.08235294, 0.2627451 , 0.43137255]]],\n",
              "\n",
              "\n",
              "       [[[0.92156863, 0.92156863, 0.92156863],\n",
              "         [0.90588235, 0.90588235, 0.90588235],\n",
              "         [0.90980392, 0.90980392, 0.90980392],\n",
              "         ...,\n",
              "         [0.91372549, 0.91372549, 0.91372549],\n",
              "         [0.91372549, 0.91372549, 0.91372549],\n",
              "         [0.90980392, 0.90980392, 0.90980392]],\n",
              "\n",
              "        [[0.93333333, 0.93333333, 0.93333333],\n",
              "         [0.92156863, 0.92156863, 0.92156863],\n",
              "         [0.92156863, 0.92156863, 0.92156863],\n",
              "         ...,\n",
              "         [0.9254902 , 0.9254902 , 0.9254902 ],\n",
              "         [0.9254902 , 0.9254902 , 0.9254902 ],\n",
              "         [0.92156863, 0.92156863, 0.92156863]],\n",
              "\n",
              "        [[0.92941176, 0.92941176, 0.92941176],\n",
              "         [0.91764706, 0.91764706, 0.91764706],\n",
              "         [0.91764706, 0.91764706, 0.91764706],\n",
              "         ...,\n",
              "         [0.92156863, 0.92156863, 0.92156863],\n",
              "         [0.92156863, 0.92156863, 0.92156863],\n",
              "         [0.91764706, 0.91764706, 0.91764706]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.34117647, 0.38823529, 0.34901961],\n",
              "         [0.16862745, 0.2       , 0.14509804],\n",
              "         [0.0745098 , 0.09019608, 0.04313725],\n",
              "         ...,\n",
              "         [0.6627451 , 0.72156863, 0.70196078],\n",
              "         [0.71372549, 0.77254902, 0.75686275],\n",
              "         [0.7372549 , 0.79215686, 0.78823529]],\n",
              "\n",
              "        [[0.32156863, 0.37647059, 0.32156863],\n",
              "         [0.18039216, 0.22352941, 0.14117647],\n",
              "         [0.14117647, 0.17254902, 0.08627451],\n",
              "         ...,\n",
              "         [0.68235294, 0.74117647, 0.71764706],\n",
              "         [0.7254902 , 0.78431373, 0.76862745],\n",
              "         [0.73333333, 0.79215686, 0.78431373]],\n",
              "\n",
              "        [[0.33333333, 0.39607843, 0.3254902 ],\n",
              "         [0.24313725, 0.29411765, 0.18823529],\n",
              "         [0.22745098, 0.2627451 , 0.14901961],\n",
              "         ...,\n",
              "         [0.65882353, 0.71764706, 0.69803922],\n",
              "         [0.70588235, 0.76470588, 0.74901961],\n",
              "         [0.72941176, 0.78431373, 0.78039216]]],\n",
              "\n",
              "\n",
              "       [[[0.61960784, 0.74509804, 0.87058824],\n",
              "         [0.61960784, 0.73333333, 0.85490196],\n",
              "         [0.54509804, 0.65098039, 0.76078431],\n",
              "         ...,\n",
              "         [0.89411765, 0.90588235, 0.91764706],\n",
              "         [0.92941176, 0.9372549 , 0.95294118],\n",
              "         [0.93333333, 0.94509804, 0.96470588]],\n",
              "\n",
              "        [[0.66666667, 0.78431373, 0.89803922],\n",
              "         [0.6745098 , 0.78039216, 0.88627451],\n",
              "         [0.59215686, 0.69019608, 0.78823529],\n",
              "         ...,\n",
              "         [0.90980392, 0.90980392, 0.9254902 ],\n",
              "         [0.96470588, 0.96470588, 0.98039216],\n",
              "         [0.96470588, 0.96862745, 0.98431373]],\n",
              "\n",
              "        [[0.68235294, 0.78823529, 0.88235294],\n",
              "         [0.69019608, 0.78431373, 0.87058824],\n",
              "         [0.61568627, 0.70196078, 0.78039216],\n",
              "         ...,\n",
              "         [0.90196078, 0.89803922, 0.90980392],\n",
              "         [0.98039216, 0.97647059, 0.98431373],\n",
              "         [0.96078431, 0.95686275, 0.96862745]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.12156863, 0.15686275, 0.17647059],\n",
              "         [0.11764706, 0.15294118, 0.17254902],\n",
              "         [0.10196078, 0.1372549 , 0.15686275],\n",
              "         ...,\n",
              "         [0.14509804, 0.15686275, 0.18039216],\n",
              "         [0.03529412, 0.05098039, 0.05490196],\n",
              "         [0.01568627, 0.02745098, 0.01960784]],\n",
              "\n",
              "        [[0.09019608, 0.13333333, 0.15294118],\n",
              "         [0.10588235, 0.14901961, 0.16862745],\n",
              "         [0.09803922, 0.14117647, 0.16078431],\n",
              "         ...,\n",
              "         [0.0745098 , 0.07843137, 0.09411765],\n",
              "         [0.01568627, 0.02352941, 0.01176471],\n",
              "         [0.01960784, 0.02745098, 0.01176471]],\n",
              "\n",
              "        [[0.10980392, 0.16078431, 0.18431373],\n",
              "         [0.11764706, 0.16862745, 0.19607843],\n",
              "         [0.1254902 , 0.17647059, 0.20392157],\n",
              "         ...,\n",
              "         [0.01960784, 0.02352941, 0.03137255],\n",
              "         [0.01568627, 0.01960784, 0.01176471],\n",
              "         [0.02745098, 0.03137255, 0.02745098]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.07843137, 0.05882353, 0.04705882],\n",
              "         [0.0745098 , 0.05490196, 0.04313725],\n",
              "         [0.05882353, 0.05490196, 0.04313725],\n",
              "         ...,\n",
              "         [0.03921569, 0.03529412, 0.02745098],\n",
              "         [0.04705882, 0.04313725, 0.03529412],\n",
              "         [0.05098039, 0.04705882, 0.03921569]],\n",
              "\n",
              "        [[0.08235294, 0.0627451 , 0.05098039],\n",
              "         [0.07843137, 0.0627451 , 0.05098039],\n",
              "         [0.07058824, 0.06666667, 0.04705882],\n",
              "         ...,\n",
              "         [0.03921569, 0.03529412, 0.02745098],\n",
              "         [0.03921569, 0.03529412, 0.02745098],\n",
              "         [0.04705882, 0.04313725, 0.03529412]],\n",
              "\n",
              "        [[0.08235294, 0.0627451 , 0.05098039],\n",
              "         [0.08235294, 0.06666667, 0.04705882],\n",
              "         [0.07843137, 0.07058824, 0.04313725],\n",
              "         ...,\n",
              "         [0.04705882, 0.04313725, 0.03529412],\n",
              "         [0.04705882, 0.04313725, 0.03529412],\n",
              "         [0.05098039, 0.04705882, 0.03921569]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.12941176, 0.09803922, 0.05098039],\n",
              "         [0.13333333, 0.10196078, 0.05882353],\n",
              "         [0.13333333, 0.10196078, 0.05882353],\n",
              "         ...,\n",
              "         [0.10980392, 0.09803922, 0.20392157],\n",
              "         [0.11372549, 0.09803922, 0.22745098],\n",
              "         [0.09019608, 0.07843137, 0.16470588]],\n",
              "\n",
              "        [[0.12941176, 0.09803922, 0.05490196],\n",
              "         [0.13333333, 0.10196078, 0.05882353],\n",
              "         [0.13333333, 0.10196078, 0.05882353],\n",
              "         ...,\n",
              "         [0.10588235, 0.09411765, 0.20392157],\n",
              "         [0.10588235, 0.09411765, 0.21960784],\n",
              "         [0.09803922, 0.08627451, 0.18431373]],\n",
              "\n",
              "        [[0.12156863, 0.09019608, 0.04705882],\n",
              "         [0.1254902 , 0.09411765, 0.05098039],\n",
              "         [0.12941176, 0.09803922, 0.05490196],\n",
              "         ...,\n",
              "         [0.09411765, 0.09019608, 0.19607843],\n",
              "         [0.10196078, 0.09019608, 0.20784314],\n",
              "         [0.09803922, 0.07843137, 0.18431373]]],\n",
              "\n",
              "\n",
              "       [[[0.09803922, 0.15686275, 0.04705882],\n",
              "         [0.05882353, 0.14117647, 0.01176471],\n",
              "         [0.09019608, 0.16078431, 0.07058824],\n",
              "         ...,\n",
              "         [0.23921569, 0.32156863, 0.30588235],\n",
              "         [0.36078431, 0.44313725, 0.43921569],\n",
              "         [0.29411765, 0.34901961, 0.36078431]],\n",
              "\n",
              "        [[0.04705882, 0.09803922, 0.02352941],\n",
              "         [0.07843137, 0.14509804, 0.02745098],\n",
              "         [0.09411765, 0.14117647, 0.05882353],\n",
              "         ...,\n",
              "         [0.45098039, 0.5254902 , 0.54117647],\n",
              "         [0.58431373, 0.65882353, 0.69411765],\n",
              "         [0.40784314, 0.45882353, 0.51372549]],\n",
              "\n",
              "        [[0.04705882, 0.09803922, 0.04313725],\n",
              "         [0.05882353, 0.11372549, 0.02352941],\n",
              "         [0.13333333, 0.15686275, 0.09411765],\n",
              "         ...,\n",
              "         [0.60392157, 0.6745098 , 0.71372549],\n",
              "         [0.61568627, 0.68627451, 0.75294118],\n",
              "         [0.45490196, 0.50588235, 0.59215686]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.39215686, 0.50588235, 0.31764706],\n",
              "         [0.40392157, 0.51764706, 0.32941176],\n",
              "         [0.40784314, 0.5254902 , 0.3372549 ],\n",
              "         ...,\n",
              "         [0.38039216, 0.50196078, 0.32941176],\n",
              "         [0.38431373, 0.49411765, 0.32941176],\n",
              "         [0.35686275, 0.4745098 , 0.30980392]],\n",
              "\n",
              "        [[0.40392157, 0.51764706, 0.3254902 ],\n",
              "         [0.40784314, 0.51372549, 0.3254902 ],\n",
              "         [0.41960784, 0.52941176, 0.34117647],\n",
              "         ...,\n",
              "         [0.39607843, 0.51764706, 0.34117647],\n",
              "         [0.38823529, 0.49803922, 0.32941176],\n",
              "         [0.36078431, 0.4745098 , 0.30980392]],\n",
              "\n",
              "        [[0.37254902, 0.49411765, 0.30588235],\n",
              "         [0.37254902, 0.48235294, 0.29803922],\n",
              "         [0.39607843, 0.50196078, 0.31764706],\n",
              "         ...,\n",
              "         [0.36470588, 0.48627451, 0.31372549],\n",
              "         [0.37254902, 0.48235294, 0.31764706],\n",
              "         [0.36078431, 0.47058824, 0.31372549]]],\n",
              "\n",
              "\n",
              "       [[[0.28627451, 0.30588235, 0.29411765],\n",
              "         [0.38431373, 0.40392157, 0.44313725],\n",
              "         [0.38823529, 0.41568627, 0.44705882],\n",
              "         ...,\n",
              "         [0.52941176, 0.58823529, 0.59607843],\n",
              "         [0.52941176, 0.58431373, 0.60392157],\n",
              "         [0.79607843, 0.84313725, 0.8745098 ]],\n",
              "\n",
              "        [[0.27058824, 0.28627451, 0.2745098 ],\n",
              "         [0.32941176, 0.34901961, 0.38039216],\n",
              "         [0.26666667, 0.29411765, 0.31764706],\n",
              "         ...,\n",
              "         [0.33333333, 0.37254902, 0.34901961],\n",
              "         [0.27843137, 0.32156863, 0.31372549],\n",
              "         [0.47058824, 0.52156863, 0.52941176]],\n",
              "\n",
              "        [[0.27058824, 0.28627451, 0.2745098 ],\n",
              "         [0.35294118, 0.37254902, 0.39215686],\n",
              "         [0.24313725, 0.27843137, 0.29019608],\n",
              "         ...,\n",
              "         [0.29019608, 0.31764706, 0.2745098 ],\n",
              "         [0.20784314, 0.24313725, 0.21176471],\n",
              "         [0.24313725, 0.29019608, 0.27058824]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.48235294, 0.50196078, 0.37647059],\n",
              "         [0.51764706, 0.51764706, 0.4       ],\n",
              "         [0.50588235, 0.50196078, 0.39215686],\n",
              "         ...,\n",
              "         [0.42352941, 0.41960784, 0.34509804],\n",
              "         [0.24313725, 0.23529412, 0.21568627],\n",
              "         [0.10588235, 0.10588235, 0.10980392]],\n",
              "\n",
              "        [[0.45098039, 0.4745098 , 0.35686275],\n",
              "         [0.48235294, 0.48627451, 0.37254902],\n",
              "         [0.50588235, 0.49411765, 0.38823529],\n",
              "         ...,\n",
              "         [0.45098039, 0.45490196, 0.36862745],\n",
              "         [0.25882353, 0.25490196, 0.23137255],\n",
              "         [0.10588235, 0.10588235, 0.10588235]],\n",
              "\n",
              "        [[0.45490196, 0.47058824, 0.35294118],\n",
              "         [0.4745098 , 0.47843137, 0.36862745],\n",
              "         [0.50588235, 0.50196078, 0.39607843],\n",
              "         ...,\n",
              "         [0.45490196, 0.45098039, 0.36862745],\n",
              "         [0.26666667, 0.25490196, 0.22745098],\n",
              "         [0.10588235, 0.10196078, 0.10196078]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The dataset consits of 10 classes and each of them has been added to the list names objects\n",
        "objects = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
      ],
      "metadata": {
        "id": "A-AkvVO35mom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to plot and the image and label using the index parameter\n",
        "def sample(x,y,index):\n",
        "  plt.figure(figsize=(15,2))\n",
        "  plt.imshow(x[index])\n",
        "  plt.xlabel(objects[y[index]])\n"
      ],
      "metadata": {
        "id": "HrrcVCBF6GWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sample\n",
        "sample(X_train,y_train,6768)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-O1bLy0Y6eao",
        "outputId": "74b2569c-9d5f-44ad-abc2-0d28cc380571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The sample training data is represented in a RGB model i.e the values will be in betweem 0 and 255\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DT-Px_qC-OB6",
        "outputId": "656de4f4-a2b9-4669-de54-1247157a1fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 59,  62,  63],\n",
              "         [ 43,  46,  45],\n",
              "         [ 50,  48,  43],\n",
              "         ...,\n",
              "         [158, 132, 108],\n",
              "         [152, 125, 102],\n",
              "         [148, 124, 103]],\n",
              "\n",
              "        [[ 16,  20,  20],\n",
              "         [  0,   0,   0],\n",
              "         [ 18,   8,   0],\n",
              "         ...,\n",
              "         [123,  88,  55],\n",
              "         [119,  83,  50],\n",
              "         [122,  87,  57]],\n",
              "\n",
              "        [[ 25,  24,  21],\n",
              "         [ 16,   7,   0],\n",
              "         [ 49,  27,   8],\n",
              "         ...,\n",
              "         [118,  84,  50],\n",
              "         [120,  84,  50],\n",
              "         [109,  73,  42]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[208, 170,  96],\n",
              "         [201, 153,  34],\n",
              "         [198, 161,  26],\n",
              "         ...,\n",
              "         [160, 133,  70],\n",
              "         [ 56,  31,   7],\n",
              "         [ 53,  34,  20]],\n",
              "\n",
              "        [[180, 139,  96],\n",
              "         [173, 123,  42],\n",
              "         [186, 144,  30],\n",
              "         ...,\n",
              "         [184, 148,  94],\n",
              "         [ 97,  62,  34],\n",
              "         [ 83,  53,  34]],\n",
              "\n",
              "        [[177, 144, 116],\n",
              "         [168, 129,  94],\n",
              "         [179, 142,  87],\n",
              "         ...,\n",
              "         [216, 184, 140],\n",
              "         [151, 118,  84],\n",
              "         [123,  92,  72]]],\n",
              "\n",
              "\n",
              "       [[[154, 177, 187],\n",
              "         [126, 137, 136],\n",
              "         [105, 104,  95],\n",
              "         ...,\n",
              "         [ 91,  95,  71],\n",
              "         [ 87,  90,  71],\n",
              "         [ 79,  81,  70]],\n",
              "\n",
              "        [[140, 160, 169],\n",
              "         [145, 153, 154],\n",
              "         [125, 125, 118],\n",
              "         ...,\n",
              "         [ 96,  99,  78],\n",
              "         [ 77,  80,  62],\n",
              "         [ 71,  73,  61]],\n",
              "\n",
              "        [[140, 155, 164],\n",
              "         [139, 146, 149],\n",
              "         [115, 115, 112],\n",
              "         ...,\n",
              "         [ 79,  82,  64],\n",
              "         [ 68,  70,  55],\n",
              "         [ 67,  69,  55]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[175, 167, 166],\n",
              "         [156, 154, 160],\n",
              "         [154, 160, 170],\n",
              "         ...,\n",
              "         [ 42,  34,  36],\n",
              "         [ 61,  53,  57],\n",
              "         [ 93,  83,  91]],\n",
              "\n",
              "        [[165, 154, 128],\n",
              "         [156, 152, 130],\n",
              "         [159, 161, 142],\n",
              "         ...,\n",
              "         [103,  93,  96],\n",
              "         [123, 114, 120],\n",
              "         [131, 121, 131]],\n",
              "\n",
              "        [[163, 148, 120],\n",
              "         [158, 148, 122],\n",
              "         [163, 156, 133],\n",
              "         ...,\n",
              "         [143, 133, 139],\n",
              "         [143, 134, 142],\n",
              "         [143, 133, 144]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[113, 120, 112],\n",
              "         [111, 118, 111],\n",
              "         [105, 112, 106],\n",
              "         ...,\n",
              "         [ 72,  81,  80],\n",
              "         [ 72,  80,  79],\n",
              "         [ 72,  80,  79]],\n",
              "\n",
              "        [[111, 118, 110],\n",
              "         [104, 111, 104],\n",
              "         [ 99, 106,  98],\n",
              "         ...,\n",
              "         [ 68,  75,  73],\n",
              "         [ 70,  76,  75],\n",
              "         [ 78,  84,  82]],\n",
              "\n",
              "        [[106, 113, 105],\n",
              "         [ 99, 106,  98],\n",
              "         [ 95, 102,  94],\n",
              "         ...,\n",
              "         [ 78,  85,  83],\n",
              "         [ 79,  85,  83],\n",
              "         [ 80,  86,  84]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 35, 178, 235],\n",
              "         [ 40, 176, 239],\n",
              "         [ 42, 176, 241],\n",
              "         ...,\n",
              "         [ 99, 177, 219],\n",
              "         [ 79, 147, 197],\n",
              "         [ 89, 148, 189]],\n",
              "\n",
              "        [[ 57, 182, 234],\n",
              "         [ 44, 184, 250],\n",
              "         [ 50, 183, 240],\n",
              "         ...,\n",
              "         [156, 182, 200],\n",
              "         [141, 177, 206],\n",
              "         [116, 149, 175]],\n",
              "\n",
              "        [[ 98, 197, 237],\n",
              "         [ 64, 189, 252],\n",
              "         [ 69, 192, 245],\n",
              "         ...,\n",
              "         [188, 195, 206],\n",
              "         [119, 135, 147],\n",
              "         [ 61,  79,  90]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 73,  79,  77],\n",
              "         [ 53,  63,  68],\n",
              "         [ 54,  68,  80],\n",
              "         ...,\n",
              "         [ 17,  40,  64],\n",
              "         [ 21,  36,  51],\n",
              "         [ 33,  48,  49]],\n",
              "\n",
              "        [[ 61,  68,  75],\n",
              "         [ 55,  70,  86],\n",
              "         [ 57,  79, 103],\n",
              "         ...,\n",
              "         [ 24,  48,  72],\n",
              "         [ 17,  35,  53],\n",
              "         [  7,  23,  32]],\n",
              "\n",
              "        [[ 44,  56,  73],\n",
              "         [ 46,  66,  88],\n",
              "         [ 49,  77, 105],\n",
              "         ...,\n",
              "         [ 27,  52,  77],\n",
              "         [ 21,  43,  66],\n",
              "         [ 12,  31,  50]]],\n",
              "\n",
              "\n",
              "       [[[189, 211, 240],\n",
              "         [186, 208, 236],\n",
              "         [185, 207, 235],\n",
              "         ...,\n",
              "         [175, 195, 224],\n",
              "         [172, 194, 222],\n",
              "         [169, 194, 220]],\n",
              "\n",
              "        [[194, 210, 239],\n",
              "         [191, 207, 236],\n",
              "         [190, 206, 235],\n",
              "         ...,\n",
              "         [173, 192, 220],\n",
              "         [171, 191, 218],\n",
              "         [167, 190, 216]],\n",
              "\n",
              "        [[208, 219, 244],\n",
              "         [205, 216, 240],\n",
              "         [204, 215, 239],\n",
              "         ...,\n",
              "         [175, 191, 217],\n",
              "         [172, 190, 216],\n",
              "         [169, 191, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[207, 199, 181],\n",
              "         [203, 195, 175],\n",
              "         [203, 196, 173],\n",
              "         ...,\n",
              "         [135, 132, 127],\n",
              "         [162, 158, 150],\n",
              "         [168, 163, 151]],\n",
              "\n",
              "        [[198, 190, 170],\n",
              "         [189, 181, 159],\n",
              "         [180, 172, 147],\n",
              "         ...,\n",
              "         [178, 171, 160],\n",
              "         [175, 169, 156],\n",
              "         [175, 169, 154]],\n",
              "\n",
              "        [[198, 189, 173],\n",
              "         [189, 181, 162],\n",
              "         [178, 170, 149],\n",
              "         ...,\n",
              "         [195, 184, 169],\n",
              "         [196, 189, 171],\n",
              "         [195, 190, 171]]],\n",
              "\n",
              "\n",
              "       [[[229, 229, 239],\n",
              "         [236, 237, 247],\n",
              "         [234, 236, 247],\n",
              "         ...,\n",
              "         [217, 219, 233],\n",
              "         [221, 223, 234],\n",
              "         [222, 223, 233]],\n",
              "\n",
              "        [[222, 221, 229],\n",
              "         [239, 239, 249],\n",
              "         [233, 234, 246],\n",
              "         ...,\n",
              "         [223, 223, 236],\n",
              "         [227, 228, 238],\n",
              "         [210, 211, 220]],\n",
              "\n",
              "        [[213, 206, 211],\n",
              "         [234, 232, 239],\n",
              "         [231, 233, 244],\n",
              "         ...,\n",
              "         [220, 220, 232],\n",
              "         [220, 219, 232],\n",
              "         [202, 203, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[150, 143, 135],\n",
              "         [140, 135, 127],\n",
              "         [132, 127, 120],\n",
              "         ...,\n",
              "         [224, 222, 218],\n",
              "         [230, 228, 225],\n",
              "         [241, 241, 238]],\n",
              "\n",
              "        [[137, 132, 126],\n",
              "         [130, 127, 120],\n",
              "         [125, 121, 115],\n",
              "         ...,\n",
              "         [181, 180, 178],\n",
              "         [202, 201, 198],\n",
              "         [212, 211, 207]],\n",
              "\n",
              "        [[122, 119, 114],\n",
              "         [118, 116, 110],\n",
              "         [120, 116, 111],\n",
              "         ...,\n",
              "         [179, 177, 173],\n",
              "         [164, 164, 162],\n",
              "         [163, 163, 161]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the images to a number from 0 to 1. Image has 3 channels (R,G,B) and each value in the channel can range from 0 to 255. Hence to normalize in 0-->1 range,\n",
        "#we need to divide it by 255X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0"
      ],
      "metadata": {
        "id": "eiDJZUj-7v2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlOAiWme-LdP",
        "outputId": "58c12a8e-215e-4dd9-a3a7-ec434972e3aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 59,  62,  63],\n",
              "         [ 43,  46,  45],\n",
              "         [ 50,  48,  43],\n",
              "         ...,\n",
              "         [158, 132, 108],\n",
              "         [152, 125, 102],\n",
              "         [148, 124, 103]],\n",
              "\n",
              "        [[ 16,  20,  20],\n",
              "         [  0,   0,   0],\n",
              "         [ 18,   8,   0],\n",
              "         ...,\n",
              "         [123,  88,  55],\n",
              "         [119,  83,  50],\n",
              "         [122,  87,  57]],\n",
              "\n",
              "        [[ 25,  24,  21],\n",
              "         [ 16,   7,   0],\n",
              "         [ 49,  27,   8],\n",
              "         ...,\n",
              "         [118,  84,  50],\n",
              "         [120,  84,  50],\n",
              "         [109,  73,  42]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[208, 170,  96],\n",
              "         [201, 153,  34],\n",
              "         [198, 161,  26],\n",
              "         ...,\n",
              "         [160, 133,  70],\n",
              "         [ 56,  31,   7],\n",
              "         [ 53,  34,  20]],\n",
              "\n",
              "        [[180, 139,  96],\n",
              "         [173, 123,  42],\n",
              "         [186, 144,  30],\n",
              "         ...,\n",
              "         [184, 148,  94],\n",
              "         [ 97,  62,  34],\n",
              "         [ 83,  53,  34]],\n",
              "\n",
              "        [[177, 144, 116],\n",
              "         [168, 129,  94],\n",
              "         [179, 142,  87],\n",
              "         ...,\n",
              "         [216, 184, 140],\n",
              "         [151, 118,  84],\n",
              "         [123,  92,  72]]],\n",
              "\n",
              "\n",
              "       [[[154, 177, 187],\n",
              "         [126, 137, 136],\n",
              "         [105, 104,  95],\n",
              "         ...,\n",
              "         [ 91,  95,  71],\n",
              "         [ 87,  90,  71],\n",
              "         [ 79,  81,  70]],\n",
              "\n",
              "        [[140, 160, 169],\n",
              "         [145, 153, 154],\n",
              "         [125, 125, 118],\n",
              "         ...,\n",
              "         [ 96,  99,  78],\n",
              "         [ 77,  80,  62],\n",
              "         [ 71,  73,  61]],\n",
              "\n",
              "        [[140, 155, 164],\n",
              "         [139, 146, 149],\n",
              "         [115, 115, 112],\n",
              "         ...,\n",
              "         [ 79,  82,  64],\n",
              "         [ 68,  70,  55],\n",
              "         [ 67,  69,  55]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[175, 167, 166],\n",
              "         [156, 154, 160],\n",
              "         [154, 160, 170],\n",
              "         ...,\n",
              "         [ 42,  34,  36],\n",
              "         [ 61,  53,  57],\n",
              "         [ 93,  83,  91]],\n",
              "\n",
              "        [[165, 154, 128],\n",
              "         [156, 152, 130],\n",
              "         [159, 161, 142],\n",
              "         ...,\n",
              "         [103,  93,  96],\n",
              "         [123, 114, 120],\n",
              "         [131, 121, 131]],\n",
              "\n",
              "        [[163, 148, 120],\n",
              "         [158, 148, 122],\n",
              "         [163, 156, 133],\n",
              "         ...,\n",
              "         [143, 133, 139],\n",
              "         [143, 134, 142],\n",
              "         [143, 133, 144]]],\n",
              "\n",
              "\n",
              "       [[[255, 255, 255],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         ...,\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253],\n",
              "         [253, 253, 253]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         ...,\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255],\n",
              "         [255, 255, 255]],\n",
              "\n",
              "        [[255, 255, 255],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         ...,\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254],\n",
              "         [254, 254, 254]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[113, 120, 112],\n",
              "         [111, 118, 111],\n",
              "         [105, 112, 106],\n",
              "         ...,\n",
              "         [ 72,  81,  80],\n",
              "         [ 72,  80,  79],\n",
              "         [ 72,  80,  79]],\n",
              "\n",
              "        [[111, 118, 110],\n",
              "         [104, 111, 104],\n",
              "         [ 99, 106,  98],\n",
              "         ...,\n",
              "         [ 68,  75,  73],\n",
              "         [ 70,  76,  75],\n",
              "         [ 78,  84,  82]],\n",
              "\n",
              "        [[106, 113, 105],\n",
              "         [ 99, 106,  98],\n",
              "         [ 95, 102,  94],\n",
              "         ...,\n",
              "         [ 78,  85,  83],\n",
              "         [ 79,  85,  83],\n",
              "         [ 80,  86,  84]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 35, 178, 235],\n",
              "         [ 40, 176, 239],\n",
              "         [ 42, 176, 241],\n",
              "         ...,\n",
              "         [ 99, 177, 219],\n",
              "         [ 79, 147, 197],\n",
              "         [ 89, 148, 189]],\n",
              "\n",
              "        [[ 57, 182, 234],\n",
              "         [ 44, 184, 250],\n",
              "         [ 50, 183, 240],\n",
              "         ...,\n",
              "         [156, 182, 200],\n",
              "         [141, 177, 206],\n",
              "         [116, 149, 175]],\n",
              "\n",
              "        [[ 98, 197, 237],\n",
              "         [ 64, 189, 252],\n",
              "         [ 69, 192, 245],\n",
              "         ...,\n",
              "         [188, 195, 206],\n",
              "         [119, 135, 147],\n",
              "         [ 61,  79,  90]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 73,  79,  77],\n",
              "         [ 53,  63,  68],\n",
              "         [ 54,  68,  80],\n",
              "         ...,\n",
              "         [ 17,  40,  64],\n",
              "         [ 21,  36,  51],\n",
              "         [ 33,  48,  49]],\n",
              "\n",
              "        [[ 61,  68,  75],\n",
              "         [ 55,  70,  86],\n",
              "         [ 57,  79, 103],\n",
              "         ...,\n",
              "         [ 24,  48,  72],\n",
              "         [ 17,  35,  53],\n",
              "         [  7,  23,  32]],\n",
              "\n",
              "        [[ 44,  56,  73],\n",
              "         [ 46,  66,  88],\n",
              "         [ 49,  77, 105],\n",
              "         ...,\n",
              "         [ 27,  52,  77],\n",
              "         [ 21,  43,  66],\n",
              "         [ 12,  31,  50]]],\n",
              "\n",
              "\n",
              "       [[[189, 211, 240],\n",
              "         [186, 208, 236],\n",
              "         [185, 207, 235],\n",
              "         ...,\n",
              "         [175, 195, 224],\n",
              "         [172, 194, 222],\n",
              "         [169, 194, 220]],\n",
              "\n",
              "        [[194, 210, 239],\n",
              "         [191, 207, 236],\n",
              "         [190, 206, 235],\n",
              "         ...,\n",
              "         [173, 192, 220],\n",
              "         [171, 191, 218],\n",
              "         [167, 190, 216]],\n",
              "\n",
              "        [[208, 219, 244],\n",
              "         [205, 216, 240],\n",
              "         [204, 215, 239],\n",
              "         ...,\n",
              "         [175, 191, 217],\n",
              "         [172, 190, 216],\n",
              "         [169, 191, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[207, 199, 181],\n",
              "         [203, 195, 175],\n",
              "         [203, 196, 173],\n",
              "         ...,\n",
              "         [135, 132, 127],\n",
              "         [162, 158, 150],\n",
              "         [168, 163, 151]],\n",
              "\n",
              "        [[198, 190, 170],\n",
              "         [189, 181, 159],\n",
              "         [180, 172, 147],\n",
              "         ...,\n",
              "         [178, 171, 160],\n",
              "         [175, 169, 156],\n",
              "         [175, 169, 154]],\n",
              "\n",
              "        [[198, 189, 173],\n",
              "         [189, 181, 162],\n",
              "         [178, 170, 149],\n",
              "         ...,\n",
              "         [195, 184, 169],\n",
              "         [196, 189, 171],\n",
              "         [195, 190, 171]]],\n",
              "\n",
              "\n",
              "       [[[229, 229, 239],\n",
              "         [236, 237, 247],\n",
              "         [234, 236, 247],\n",
              "         ...,\n",
              "         [217, 219, 233],\n",
              "         [221, 223, 234],\n",
              "         [222, 223, 233]],\n",
              "\n",
              "        [[222, 221, 229],\n",
              "         [239, 239, 249],\n",
              "         [233, 234, 246],\n",
              "         ...,\n",
              "         [223, 223, 236],\n",
              "         [227, 228, 238],\n",
              "         [210, 211, 220]],\n",
              "\n",
              "        [[213, 206, 211],\n",
              "         [234, 232, 239],\n",
              "         [231, 233, 244],\n",
              "         ...,\n",
              "         [220, 220, 232],\n",
              "         [220, 219, 232],\n",
              "         [202, 203, 215]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[150, 143, 135],\n",
              "         [140, 135, 127],\n",
              "         [132, 127, 120],\n",
              "         ...,\n",
              "         [224, 222, 218],\n",
              "         [230, 228, 225],\n",
              "         [241, 241, 238]],\n",
              "\n",
              "        [[137, 132, 126],\n",
              "         [130, 127, 120],\n",
              "         [125, 121, 115],\n",
              "         ...,\n",
              "         [181, 180, 178],\n",
              "         [202, 201, 198],\n",
              "         [212, 211, 207]],\n",
              "\n",
              "        [[122, 119, 114],\n",
              "         [118, 116, 110],\n",
              "         [120, 116, 111],\n",
              "         ...,\n",
              "         [179, 177, 173],\n",
              "         [164, 164, 162],\n",
              "         [163, 163, 161]]]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple Artificial Neural Network Model to classify the image into the 10 categories we have defined above\n",
        "model = models.Sequential([\n",
        "        # Flattens the input. Flattening makes it a single column of rows\n",
        "        layers.Flatten(input_shape=(32,32,3)),\n",
        "        # Creating two hidden layers with 3000 neuron in the first hidden layer and using the Relu Activation Function\n",
        "        layers.Dense(3000, activation='relu'),\n",
        "        # Second Hidden layer with 1000 neuron in the second hidden layer and Relu as Activation function\n",
        "        layers.Dense(1000, activation='relu'),\n",
        "        # Classifying into 10 categories each of category\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "# Compile the model with adam optimizer,\n",
        "# sparse_categorical_crossentropy : produces a category index of the most likely matching category.\n",
        "# model will be complied and showed output in terms of accuracy\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "# Train the model with epoch5\n",
        "model.fit(X_train, y_train, epochs=5)\n",
        "# model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zz2DlrJl-1Vt",
        "outputId": "ac6c3bc8-2da3-4eed-e7f4-38e9bd2b8656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 351s 224ms/step - loss: 28.5525 - accuracy: 0.1304\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 341s 218ms/step - loss: 2.3064 - accuracy: 0.0989\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 343s 220ms/step - loss: 2.3036 - accuracy: 0.0994\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 341s 218ms/step - loss: 2.3030 - accuracy: 0.0980\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 341s 218ms/step - loss: 2.3029 - accuracy: 0.0987\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb137702c50>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test data\n",
        "predictions = model.predict(X_test)\n",
        "# Get the predicted labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rys5Xt95JnBc",
        "outputId": "627c0dc0-a1e6-4808-99fa-32ab0d2a4941"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 9s 28ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test accuracy: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWws7jcc5fRr",
        "outputId": "4d55063c-736c-4846-f3f7-47ab808c533d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 10s 31ms/step - loss: 2.3027 - accuracy: 0.1000\n",
            "Test accuracy: 10.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#convolution Model using the same Training data and Testing data from CIFAR-10 Dataset\n",
        "    #Creating two Convolution Layers with kernel size 3x3\n",
        "    #Keras layer class used to define a 2D convolutional layer\n",
        "    #filter - parameter specifies the number of filters or convolutional kernels that will be used in this layer\n",
        "    #Activation Function - the activation function applied to the output of this convolutional layer.\n",
        "    #input-shape- the shape of the input data that will be fed into this layer. In this case, it's a 32x32-pixel image with 3 color channels\n",
        "model2 = models.Sequential([\n",
        "\n",
        "    layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    #Second Convolution Layer\n",
        "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    #Flatten the layer and creating the dense layer for classification into 10 categories\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "glrd5otfKcX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "model2.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qUKiyRGiLQSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(X_train, y_train, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPH2-RHRLT_H",
        "outputId": "3fb5b38f-dbb5-48a8-f6a8-553f24329e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1563/1563 [==============================] - 65s 41ms/step - loss: 0.9933 - accuracy: 0.6545\n",
            "Epoch 2/5\n",
            "1563/1563 [==============================] - 58s 37ms/step - loss: 0.9243 - accuracy: 0.6785\n",
            "Epoch 3/5\n",
            "1563/1563 [==============================] - 59s 37ms/step - loss: 0.8616 - accuracy: 0.6983\n",
            "Epoch 4/5\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.7958 - accuracy: 0.7231\n",
            "Epoch 5/5\n",
            "1563/1563 [==============================] - 59s 38ms/step - loss: 0.7510 - accuracy: 0.7378\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb100f53e20>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    }
  ]
}